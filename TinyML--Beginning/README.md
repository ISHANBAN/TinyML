# TinyML-
It is a sound-based gesture control project – a simple example of embedded signal processing, often used in beginner TinyML or IoT projects. For implementing this project, an Arduino UNO board, a LED bulb, a KY-038 Sound Sensor module, a breadboard, and a USB Type-B cable to power the board. The code is implemented through Arduino IDE. The code actually acts like a clap switch connected to pin A0. It detects two claps within 400 milliseconds. If two claps are detected and the LED is off then it turns on. It works vice-versa if the LED is on initially. The LED is connected to pin 13 of the UNO board. If only one clap is detected then the status of the LED will not change. So it can be noticed that it is not a Machine Learning code. It uses simple if-else logic to detect patterns in sensors input. There is no training, inference, or model involved. It’s a simple rule-based sound-detection code. But, it mimics the basic classification logic which acts as a perfect foundation for TinyML. 
